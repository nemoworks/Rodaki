# 说明
此文档概述该rodaki项目所有组件的运行说明，具体每个组件的详细说明可见各个部分的readme文档

## 环境依赖
+ 机器上装好java(版本11)、maven、jmeter、python3、python3-pip等程序。

+ python安装依赖：pip install -r requirements.txt

## 目录层次
假设每个组件以组件名为命令的文件夹存放：
``` bash
├── cleaneddatas
├── datas
├── apache-jmeter-5.4.1
├── DataSplit
├── webflux
├── deploy
├── jmeter
├── TrafficFlowForecast
```

## 代码运行
将按照顺序，依次介绍
### DataSplit
这个目录的split.py负责对原始csv数据文件进行拆分，按照站点进行分类，生成jmeter读取的txt文件

运行命令：

`cd DataSplit` 

`python split.py`

然后`cleaneddatas datas`两个目录就会有相应文件

详细说明可见该目录的[readme](/DataSplit/readme.md)
### 支撑环境部署
整个系统需要用到flink、kafka、iotdb、kibana、elasticsearch、ditto等软件环境

目前这些软件以docker容器运行在集群里

相应的部署文件放在了deploy目录下

详细说明可见该目录的[readme](/deploy/readme.md)
### webflux接收程序
webflux接收程序负责接收数据文件的上传，然后将数据写入kafka队列

`cd webflux`

`mvn spring-boot:run`

就会启动8000端口上的后台接收程序

详细说明可见该目录的[readme](/webflux/readme.md)
### jmeter发送程序
jmeter负责使用多线程模拟真实环境下的站点数据上传过程，因此需要有webflux接收程序提前运行

`cd apache-jmeter-5.4.1`

`./bin/jmeter -n -t ../jmeter/中创数据模拟v2.jmx`

即可模拟前端上传过程

### TrafficFlowForecast门架车流量预测
TrafficFlowForecast负责从elasticsearch数据库读取车流量、预测并写回
详细说明可见该目录的[readme](/TrafficFlowForecast/readme.md)

